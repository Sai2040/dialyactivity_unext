20-9-23

SPARK IS A FRAMEWORK.

BIG DATA---> BDP-----> PROCESSING, STORAGE.

PROCESSING----> FRAMEWORK, CLUSTER.

STORAGE---> DISTRIBUTED, I/O OPERATIONS.

BDP:
1) MICROSOFT---> HD INSIGHT.|
2)AMAZON---> EMR            |===> DATA BRICKS
3) GCP----> BIG QUERY       |        |
                                   OWN CLOUD
STORAGE<---- HADOOP---> JAVA

MEMORY<---- SPARK----> PYHTON/SQL.

HADOOP REQUIRE ONLY COMMUNITY HARDWARE.

SAPRK USES RAM, 100 TIMES FASTER THAN HADOOP.

SPARK EVEN USES JAVA,R,SCALA.

IN SPARK, FOR DIDTRIBUTED SYSTEMS --->COMPUTING---> CLUSTERING--> MASTER SLAVE USES SSH, TCP PROTOCOL FOR COMMUNICATION.

APPLICATON---> INTERACTIVE,PROGRAM.

LIFECYCLE OF SPARK:

1.SUBIT AN APPLICATION.
2.INITIALISATION.

WHEN THE APPLICATION IS SUBMITTED, SPARK PROGRAM LAUNCH ON A CLUSTER NOTE.

THE DRIVER PROGRAM INITIALIZE SPARK CONTEXT, WHICH IS RESPONSIBLE FOR COORDINATING JOB EXECUTION.

YOUR SPARK APPLICATION IS DIVIDED INTO ONE OR MORE JOBS.

EACH JOB CONSISTS OF STAGES.

STAGES IS CREATED FOR RDD TRANSFORMATIONS, REQUIRE DATA SHUFFLING.

DAG(GRAPH) GENERATION:

SPARK CONSTRUCTS A DAG, THAT REPRESENTS THE LOGICAL EXECTION PLAN FOR THE APPLICATION.

DAG CONTAINS INFO ABOUT THE DEPEDENCIES BTW STAGES AND TASKS.

TASK SCHEDULING:

THE SCHEDULER TAKES THE DAG AND SCHEDULES TASKS FOR EXECTIONS.

TASK EXECUTION:

TASKS ARE EXECUTED ON WORKER(SLAVE) NOTE IN PARALLEL OR DISTRIBUTED MODE.

SHUFFLING AND DATA EXCHANGE: (OPTIONAL)

EG: (REDUCE BY KEY.)

TASK COMPLTETION PHASE:

AS TASK COMPLETES, THEY PRODUCE IMMEDIATE RESULTS.

THESE RESULTS ARE CACHED OR PERSISITED IN MANUALLY, FOR SUBSEQUENT TASKS OR STAGES TO USE, WHICH REDUCES THE RECOMPILATION.

STAGE COMPLETION PHASE:

STAGES ARE MARKED AS COMPLETE, WHEN ALL OF THEIR TASKS FINISHED SUCCESFULLY.

JOB COMPLETION:

CLEAN UP:

DEALLOCATE RESOURCES LIKE GARBAGE COLLECTOR.


=> APP--> NODE (WORKER)--> EXECUTOR.
    |
   JOB-----> READ(), WRITE(),,,, FOR RDD, COLLECT() & COUNT()
    |
   STAGE-------> MAP(),FILTER()
    |
   TASK
   /   \
THREAD  EXECUTOR

=> TASK: A SINGLE OPERATION APPLIED TO A SINGLE PARTITION. EACH TASK IS EXECUTED IN A SINGLE THREAD IN A EXECUTOR.

WHY SPARK:

-> UNIFIED ANALYTICS.

-> BATCH & PARALLEL

-> REAL TIME ANALYTICS

->STREAMING

->SUPPORTS INTERACTIVE SQL.

->STRUCTURED, UNSTRUCTURED, SEMI STRUCTURED.

->GRAPH ORIENTED OPEARATIONS.

->ML

->POLYLANG.


 




  





